- publication:
  title: "An Extended Study of Human-like Behavior under Adversarial Training"
  authors: <b>Paul Gavrikov</b>, Janis Keuper, Margret Keuper
  time: 2023
  short: "Our analysis reveals how different forms of adversarial training (AT) affect human-like behavior of CNNs and Transformers. Additionally, we propose a hypothesis of why AT increases shape bias and in which scenarios it can improve out-of-distribution generalization from a frequency perspective."
  conference: "CVPR Workshops, 2023"
  details: <a href="https://openaccess.thecvf.com/content/CVPR2023W/AML/html/Gavrikov_An_Extended_Study_of_Human-Like_Behavior_Under_Adversarial_Training_CVPRW_2023_paper.html">paper</a> / <a href="https://arxiv.org/abs/2303.12669">arXiv</a>
  image: images/small/tn_atshapebias.png
- publication:
  title: "The Power of Linear Combinations: Learning with Random Convolutions"
  authors: <b>Paul Gavrikov</b>, Janis Keuper
  time: 2023
  short: "We question if learning spatial convolution filters is necessary. Even with default i.i.d. random inits, we can achieve 75.66% validation acc with ResNet-50 on ImageNet without ever learning any spatial convolution weight. Additionally, random filters can be more robust against adversarial attacks than learned filters."
  conference: ""
  details: <a href="https://arxiv.org/abs/2301.11360">arXiv</a>
  image: images/small/tn_1x1_conv.png
- publication:
  title: "Does Medical Imaging learn different Convolution Filters?"
  authors: <b>Paul Gavrikov</b>, Janis Keuper
  time: 2022
  short: "Earlier, we showed that, on average, convolution filters only show minor drifts when comparing various dimensions, including the learned task, image domain, or dataset. However, medical imaging models showed significant outliers through spikey filter distributions. We revisit this observation and perform an in-depth analysis of medical imaging models."
  conference: "NeurIPS Workshops, 2022"
  details: <a href="https://arxiv.org/abs/2210.13799">arXiv</a>
  image: images/small/tn_medicalfilters.png
- publication:
  title: "Robust Models are less Over-Confident"
  authors: Julia Grabinski, <b>Paul Gavrikov</b>, Janis Keuper, Margret Keuper
  time: 2022
  short: "Adversarial Training (AT) leads to models that are significantly less overconfident with their decisions, even on clean data, than non-robust models. The analysis shows that not only AT, but also the models' building blocks (like activation functions and pooling) have a strong influence on the models' prediction confidences."
  conference: "NeurIPS, 2022 & ICML Workshops, 2022"
  details: <a href="https://arxiv.org/abs/2210.05938">arXiv</a> / <a href="https://github.com/GeJulia/robustness_confidences_evaluation">code</a>
  image: images/small/tn_robustconf.png
- publication:
  title: "Adversarial Robustness through the Lens of Convolutional Filters"
  authors: <b>Paul Gavrikov</b>, Janis Keuper
  conference: "CVPR Workshops, 2022"
  short: "We investigate 3x3 convolution filters that form in adversarially-trained robust models and find that these models form more diverse, less sparse, and more orthogonal filters than their normal counterparts. The largest differences are found in the deepest layers and the very first convolution layer which forms highly distinct thresholding filters."
  time: 2022
  details: <a href="https://openaccess.thecvf.com/content/CVPR2022W/ArtOfRobust/html/Gavrikov_Adversarial_Robustness_Through_the_Lens_of_Convolutional_Filters_CVPRW_2022_paper.html">paper</a> / <a href="https://arxiv.org/abs/2204.02481">arXiv</a> / <a href="https://github.com/paulgavrikov/cvpr22w_RobustnessThroughTheLens">code</a>
  image: images/small/tn_advfilter.png
- publication:
  title: "CNN Filter DB: An Empirical Investigation of Trained Convolutional Filters"
  type: <font color="red"><strong>Oral Presentation</strong></font>
  authors: <b>Paul Gavrikov</b>, Janis Keuper
  conference: "CVPR, 2022"
  short: "We collected and publicly provided a dataset with over 1.4 billion 3x3 convolution filters from hundreds of trained CNNs. Our observations show that - surprisingly - models learn highly similar filter pattern distributions independent of task and dataset, but differ by model architecture. We also propose methods to measure the quality of filters to detect overparameterization or underfitting and show that many publicly available models suffer from \"degenerated\" filters."
  time: 2022
  details: <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Gavrikov_CNN_Filter_DB_An_Empirical_Investigation_of_Trained_Convolutional_Filters_CVPR_2022_paper.html">paper</a> / <a href="https://arxiv.org/abs/2203.15331">arXiv</a> / <a href="https://github.com/paulgavrikov/CNN-Filter-DB/">code</a>
  image: images/small/tn_cnnfilterdb.png
- publication:
  title: "An Empirical Investigation of Model-to-Model Distribution Shifts in Trained Convolutional Filters"
  authors: <b>Paul Gavrikov</b>, Janis Keuper
  conference: "NeurIPS Workshops, 2021"
  time: 2021
  short: "This paper looks at distribution shifts in filter weights used for various computer vision tasks. We collected data from hundreds of trained CNNs and analyzed the distribution shifts along different axes of meta-parameters. We found interesting distribution shifts between trained filters, and argue that this is a valuable source for further investigation into understanding the impact of shifts in the input data on the generalization abilities of CNN models."
  details: <a href="https://openreview.net/forum?id=2st0AzxC3mh">paper</a> / <a href="https://arxiv.org/abs/2201.08465">arXiv</a> / <a href="https://github.com/paulgavrikov/CNN-Filter-DB/">code</a>
  image: images/small/tn_empirical.png
- publication:
  title: "A Low Power and Low Latency Scan Algorithm for Bluetooth Low Energy Radios with Energy Detection Mechanisms"
  type: <font color="red"><strong>Best Paper Award</strong></font>
  authors: <b>Paul Gavrikov</b>, Matthias Lai, Thomas Wendt
  conference: "APWiMob, 2019"
  short: "A new, more efficient algorithm for Bluetooth scanning is presented that uses less power and can scale with incoming network traffic. The algorithm does not require any changes to advertisers, so it is compatible with existing devices, and performance evaluation shows that it is more efficient than existing methods."
  time: 2019
  details: <a href="https://ieeexplore.ieee.org/document/8964210">paper</a>
  image: images/small/tn_ble_scan.png
- publication:
  title: "Exploring non-idealities in real device implementations of Bluetooth Mesh"
  authors: <b>Paul Gavrikov</b>, Matthias Lai, Thomas Wendt
  conference: "Wireless Telecommunications Symposium 2019 (presentation) and IJITN"
  time: 2019
  short: "We compare the performance of Bluetooth Mesh implementations on real chipsets against the ideal implementation of the specification. It is shown that there are non-idealities in the underlying Bluetooth Low Energy specification in real chipsets and in the implementation of Mesh, which introduces an unruly transmission as well as reception behavior. These effects lead to an impact on transmission rate, reception rate, latency, as well as a more significant impact on the average power consumption."
  details: <a href="https://www.igi-global.com/article/exploring-non-idealities-in-real-device-implementations-of-bluetooth-mesh/265148">paper</a>
  image: images/small/tn_ble_nonidealities.png
- publication:
  title: "Using Bluetooth Low Energy to trigger a robust ultra-low power FSK wake-up receiver"
  authors: <b>Paul Gavrikov</b>, Pascal E. Verboket, Tolgay Ungan, Markus MÃ¼ller, Matthias Lai, Christian Schindelhauer, Leonhard M. Reindl, Thomas Wendt
  conference: ICECS, 2018
  time: 2018
  short: "We discuss a new approach to using BLE packets to create an FSK-like addressable wake-up packet. A wake-up receiver system was developed from off-the-shelf components to detect these packets. This system is more robust than traditional OOK wake-up systems and has a sensitivity of -47.8 dBm at a power consumption of 18.5 uW during passive listening. The system has a latency of 31.8 ms with a symbol rate of 1437 Baud."
  details: <a href="https://ieeexplore.ieee.org/document/8618031">paper</a>
  image: images/small/tn_wur.png
